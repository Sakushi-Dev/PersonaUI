# Schritt 3B: Aktivierungsstufen-Logik

## Ãœbersicht

Das Cortex-System aktualisiert seine Dateien (`memory.md`, `soul.md`, `relationship.md`) nicht bei jeder Nachricht, sondern an definierten **Schwellenwerten** innerhalb einer Konversation. Diese Schwellen werden als ProzentsÃ¤tze des `contextLimit` berechnet â€” der maximalen Anzahl von Nachrichten, die im Konversationskontext gehalten werden.

Drei Aktivierungsstufen (Tiers) bestimmen, wann ein Cortex-Update ausgelÃ¶st wird:

| Stufe | Default-Schwelle | Bedeutung |
|-------|:----------------:|-----------|
| Tier 1 | 50% von `contextLimit` | FrÃ¼hes Update â€” erste EindrÃ¼cke, initiale Details |
| Tier 2 | 75% von `contextLimit` | Mittleres Update â€” Vertiefung, Beziehungsentwicklung |
| Tier 3 | 95% von `contextLimit` | SpÃ¤tes Update â€” letzte Chance vor Kontext-Rotation |

Jeder Tier lÃ¶st **genau einmal** pro Konversation aus. Die Trigger-PrÃ¼fung findet **server-seitig** in `chat.py` statt, **nachdem** der Chat-Response vollstÃ¤ndig gestreamt und gespeichert wurde. Das Cortex-Update selbst lÃ¤uft als **separater, nicht-blockierender Background-Request** via `tool_use` (dokumentiert in Schritt 3A).

---

## 1. Schwellenwert-Berechnung

### 1.1 Formel

```
threshold_messages = floor(contextLimit Ã— (tier_threshold_percent / 100))
```

### 1.2 Berechnungsbeispiele

**Beispiel 1: `contextLimit = 65` (Default)**

| Tier | Schwelle (%) | Berechnung | Trigger bei Nachricht # |
|------|:------------:|-----------|:-----------------------:|
| 1 | 50% | `floor(65 Ã— 0.50)` | **32** |
| 2 | 75% | `floor(65 Ã— 0.75)` | **48** |
| 3 | 95% | `floor(65 Ã— 0.95)` | **61** |

**Beispiel 2: `contextLimit = 200` (User-konfiguriert)**

| Tier | Schwelle (%) | Berechnung | Trigger bei Nachricht # |
|------|:------------:|-----------|:-----------------------:|
| 1 | 50% | `floor(200 Ã— 0.50)` | **100** |
| 2 | 75% | `floor(200 Ã— 0.75)` | **150** |
| 3 | 95% | `floor(200 Ã— 0.95)` | **190** |

**Beispiel 3: `contextLimit = 10` (Minimum)**

| Tier | Schwelle (%) | Berechnung | Trigger bei Nachricht # |
|------|:------------:|-----------|:-----------------------:|
| 1 | 50% | `floor(10 Ã— 0.50)` | **5** |
| 2 | 75% | `floor(10 Ã— 0.75)` | **7** |
| 3 | 95% | `floor(10 Ã— 0.95)` | **9** |

### 1.3 Hinweis zu `contextLimit`

Der `contextLimit` wird vom Frontend als Einstellung gesendet und definiert die maximale Anzahl von Nachrichten im Konversationskontext. Er wird in `chat_stream` aus dem Request gelesen:

```python
# Bestehend in src/routes/chat.py (Zeile 79-84):
context_limit = data.get('context_limit', 25)
try:
    context_limit = int(context_limit)
except (TypeError, ValueError):
    context_limit = 25
context_limit = max(10, min(100, context_limit))
```

> **Hinweis:** Der aktuelle Code clampt `contextLimit` auf `max(10, min(100, ...))`. Die `user_settings.json` kann jedoch Werte wie `200` enthalten. Ob der Clamp erweitert wird, ist eine separate Diskussion â€” die Tier-Berechnung nutzt den **effektiven** (geclampten) Wert.

---

## 2. Session-State: Tracking der gefeuerten Tiers

### 2.1 Problem

Jeder Tier soll nur **einmal** pro Konversation (Session) feuern. DafÃ¼r muss der Server sich merken, welche Tiers in der aktuellen Session bereits ausgelÃ¶st wurden. Da Flask keine persistente In-Process-Session-State hat und die App neustarten kann, muss der State robust gespeichert werden.

### 2.2 LÃ¶sung: Server-seitiges In-Memory-Dictionary mit DB-Fallback

```python
# src/utils/cortex/tier_tracker.py (NEU)

"""
Cortex Tier Tracker â€” Verfolgt welche Aktivierungsstufen pro Session bereits gefeuert haben.

Nutzt ein In-Memory-Dictionary als primÃ¤ren Speicher. Bei Neustart wird der State
aus der Nachrichtenanzahl der Session re-kalkuliert (kein Datenverlust).
"""

import threading
from typing import Dict, Set

# Thread-safe In-Memory State
_lock = threading.Lock()
_fired_tiers: Dict[str, Set[int]] = {}
# Key: "{persona_id}:{session_id}" â†’ Value: set of fired tier numbers (1, 2, 3)


def _session_key(persona_id: str, session_id: int) -> str:
    """Erzeugt einen eindeutigen Key fÃ¼r die Session."""
    return f"{persona_id}:{session_id}"


def get_fired_tiers(persona_id: str, session_id: int) -> Set[int]:
    """Gibt die bereits gefeuerten Tiers fÃ¼r eine Session zurÃ¼ck."""
    key = _session_key(persona_id, session_id)
    with _lock:
        return _fired_tiers.get(key, set()).copy()


def mark_tier_fired(persona_id: str, session_id: int, tier: int) -> None:
    """Markiert einen Tier als gefeuert fÃ¼r eine Session."""
    key = _session_key(persona_id, session_id)
    with _lock:
        if key not in _fired_tiers:
            _fired_tiers[key] = set()
        _fired_tiers[key].add(tier)


def reset_session(persona_id: str, session_id: int) -> None:
    """Setzt den Tier-State fÃ¼r eine Session zurÃ¼ck (z.B. bei clear_chat)."""
    key = _session_key(persona_id, session_id)
    with _lock:
        _fired_tiers.pop(key, None)


def reset_all() -> None:
    """Setzt den gesamten Tier-State zurÃ¼ck (z.B. bei App-Restart)."""
    with _lock:
        _fired_tiers.clear()


def rebuild_from_message_count(
    persona_id: str,
    session_id: int,
    message_count: int,
    context_limit: int,
    tier_thresholds: Dict[int, int]
) -> Set[int]:
    """
    Re-kalkuliert welche Tiers basierend auf der aktuellen Nachrichtenanzahl
    bereits gefeuert haben mÃ¼ssten. Wird nach App-Neustart verwendet.

    Args:
        persona_id: Persona-ID
        session_id: Session-ID
        message_count: Aktuelle Anzahl Nachrichten in der Session
        context_limit: Aktuelles Context-Limit
        tier_thresholds: Dict {1: 50, 2: 75, 3: 95} (Prozentwerte)

    Returns:
        Set der Tiers die als gefeuert markiert wurden
    """
    key = _session_key(persona_id, session_id)
    fired = set()

    for tier_num, threshold_percent in tier_thresholds.items():
        threshold_messages = int(context_limit * (threshold_percent / 100))
        if message_count >= threshold_messages:
            fired.add(tier_num)

    with _lock:
        _fired_tiers[key] = fired

    return fired
```

### 2.3 Warum In-Memory statt DB?

| Ansatz | Vorteil | Nachteil |
|--------|---------|----------|
| **In-Memory Dict** âœ… | Schnell, einfach, kein DB-Schema | Verliert State bei Restart |
| DB-Tabelle | Persistent | Neues SQL-Schema, Migration, Overhead |
| File-basiert | Persistent, kein SQL | I/O bei jeder Nachricht |

**GewÃ¤hlter Kompromiss:** In-Memory mit **automatischem Rebuild** bei Bedarf. Wenn der Server neustartet und eine Session fortgesetzt wird, wird der Tier-State aus der aktuellen Nachrichtenanzahl re-kalkuliert. Das ist konservativ: Tiers die bereits gefeuert hÃ¤tten, werden als "gefeuert" markiert (aber nicht erneut ausgelÃ¶st). Es gehen keine Updates verloren â€” sie werden im schlimmsten Fall Ã¼bersprungen, was harmlos ist.

### 2.4 Session-Key Struktur

```
Key: "{persona_id}:{session_id}"

Beispiele:
  "default:1"           â†’ Default-Persona, Session 1
  "a1b2c3d4:5"          â†’ Custom-Persona, Session 5
```

Die Kombination aus `persona_id` und `session_id` ist notwendig, da verschiedene Personas eigene Cortex-Dateien haben und unabhÃ¤ngig getrackt werden mÃ¼ssen.

---

## 3. Server-seitige Trigger-Logik

### 3.1 Ablauf-Diagramm

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     /chat_stream Request                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. User-Nachricht empfangen                                     â”‚
â”‚  2. Chat-Stream generieren (yield chunks)                        â”‚
â”‚  3. Bot-Antwort speichern (save_message)                         â”‚
â”‚  4. SSE 'done' Event senden                                      â”‚
â”‚                                                                  â”‚
â”‚  â•â•â•â•â•â• Stream ist abgeschlossen â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                                  â”‚
â”‚  5. Tier-Check ausfÃ¼hren:                                        â”‚
â”‚     a) Message-Count fÃ¼r Session holen (get_message_count)       â”‚
â”‚     b) Cortex-Settings laden (Tiers + enabled)                   â”‚
â”‚     c) Schwellenwerte berechnen                                  â”‚
â”‚     d) PrÃ¼fen ob ein neuer Tier erreicht wurde                   â”‚
â”‚     e) Falls ja: mark_tier_fired() + Background-Update starten   â”‚
â”‚                                                                  â”‚
â”‚  6. Cortex-Update (falls getriggert):                            â”‚
â”‚     â†’ Separater Thread (non-blocking)                            â”‚
â”‚     â†’ tool_use API-Call (Schritt 3A)                             â”‚
â”‚     â†’ KI liest/schreibt Cortex-Dateien                           â”‚
â”‚     â†’ Ergebnis wird geloggt                                      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Integration in `chat.py` â€” Tier-Check nach Stream

Die Tier-PrÃ¼fung wird **nach** dem erfolgreichen Stream-Ende eingefÃ¼gt. Da der SSE-Stream zu diesem Zeitpunkt bereits alles an den Client gesendet hat, ist der Cortex-Update ein reiner Hintergrundprozess.

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MODIFIKATION: src/routes/chat.py â€” chat_stream() Funktion
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from utils.cortex.tier_tracker import get_fired_tiers, mark_tier_fired, rebuild_from_message_count
from utils.cortex.tier_checker import check_and_trigger_cortex_update
from utils.database import get_message_count

@chat_bp.route('/chat_stream', methods=['POST'])
@handle_route_error('chat_stream')
def chat_stream():
    """API-Endpoint fÃ¼r gestreamte Chat-Nachrichten via SSE"""
    data = request.get_json()
    user_message = data.get('message', '').strip()
    session_id = data.get('session_id')
    # ... bestehender Code ...

    context_limit = data.get('context_limit', 25)
    try:
        context_limit = int(context_limit)
    except (TypeError, ValueError):
        context_limit = 25
    context_limit = max(10, min(100, context_limit))

    # ... bestehender Code (conversation_history, etc.) ...

    def generate():
        chat_service = get_chat_service()
        user_msg_saved = False
        stream_success = False            # â† NEU: Tracking ob Stream erfolgreich war

        try:
            for event_type, event_data in chat_service.chat_stream(
                # ... bestehende Parameter ...
            ):
                if event_type == 'chunk':
                    if not user_msg_saved:
                        save_message(user_message, True, character_name, session_id, persona_id=persona_id)
                        user_msg_saved = True
                    yield f"data: {json.dumps({'type': 'chunk', 'text': event_data})}\n\n"

                elif event_type == 'done':
                    save_message(event_data['response'], False, character_name, session_id, persona_id=persona_id)
                    stream_success = True  # â† NEU
                    yield f"data: {json.dumps({'type': 'done', 'response': event_data['response'], 'stats': event_data['stats'], 'character_name': character_name})}\n\n"

                elif event_type == 'error':
                    # ... bestehender Error-Code ...
                    yield f"data: {json.dumps(error_payload)}\n\n"

        except Exception as e:
            log.error("Stream-Fehler: %s", e)
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)})}\n\n"

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        #  NEU: Tier-Check NACH Stream-Ende
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if stream_success:
            try:
                check_and_trigger_cortex_update(
                    persona_id=persona_id,
                    session_id=session_id,
                    context_limit=context_limit
                )
            except Exception as e:
                # Tier-Check darf niemals den Chat-Flow brechen
                log.warning("Cortex Tier-Check Fehler (non-fatal): %s", e)

    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no',
            'Connection': 'keep-alive'
        }
    )
```

### 3.3 Wichtig: Position des Tier-Checks

Der Tier-Check steht **innerhalb** der `generate()` Generator-Funktion, **nach** dem letzten `yield`. Das bedeutet:

1. Alle SSE-Events sind bereits an den Client gesendet
2. Der Client hat `done` empfangen und zeigt die Antwort an
3. Der Tier-Check lÃ¤uft noch im Server-Kontext des Generators
4. Flask schlieÃŸt den Response erst, wenn der Generator endet

```
Timeline:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
  â”‚ chunks...  â”‚ done â”‚ tier-check â”‚ background-update â”‚
  â”‚ â† Client sieht diese Events â†’ â”‚                    â”‚
                                   â”‚ â† Nicht sichtbar â†’ â”‚
```

> **Hinweis:** Der Tier-Check selbst ist schnell (DB-Query + Vergleich). Nur das eigentliche Cortex-Update wird in einen Background-Thread ausgelagert.

---

## 4. Tier-Checker Modul

### 4.1 Datei: `src/utils/cortex/tier_checker.py`

```python
"""
Cortex Tier Checker â€” PrÃ¼ft ob ein Cortex-Update ausgelÃ¶st werden soll.

Wird nach jedem erfolgreichen Chat-Response aufgerufen.
Vergleicht die aktuelle Nachrichtenanzahl mit den konfigurierten Schwellenwerten
und startet bei Bedarf ein Background-Cortex-Update.
"""

import threading
import math
from typing import Optional

from utils.logger import log
from utils.database import get_message_count
from utils.cortex.tier_tracker import get_fired_tiers, mark_tier_fired, rebuild_from_message_count


def _load_tier_config() -> dict:
    """
    LÃ¤dt die Cortex-Tier-Konfiguration.

    Returns:
        {
            "enabled": True,
            "tiers": {
                1: {"threshold": 50, "enabled": True},
                2: {"threshold": 75, "enabled": True},
                3: {"threshold": 95, "enabled": True}
            }
        }
    """
    import json
    import os

    settings_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
        'settings', 'cortex_settings.json'
    )

    defaults = {
        "enabled": True,
        "tiers": {
            "tier1": {"threshold": 50, "enabled": True},
            "tier2": {"threshold": 75, "enabled": True},
            "tier3": {"threshold": 95, "enabled": True}
        }
    }

    try:
        if os.path.exists(settings_path):
            with open(settings_path, 'r', encoding='utf-8') as f:
                saved = json.load(f)
            merged = {**defaults, **saved}
            merged['tiers'] = {**defaults['tiers'], **saved.get('tiers', {})}
        else:
            merged = defaults
    except Exception:
        merged = defaults

    # Konvertiere "tier1" â†’ 1 fÃ¼r internen Gebrauch
    config = {
        "enabled": merged.get("enabled", True),
        "tiers": {}
    }
    for key, value in merged.get("tiers", {}).items():
        tier_num = int(key.replace("tier", ""))
        config["tiers"][tier_num] = {
            "threshold": value.get("threshold", 50),
            "enabled": value.get("enabled", True)
        }

    return config


def _calculate_thresholds(context_limit: int, tier_config: dict) -> dict:
    """
    Berechnet die absoluten Nachrichtenanzahl-Schwellenwerte.

    Args:
        context_limit: Maximale Nachrichten im Kontext (z.B. 65)
        tier_config: Tier-Konfiguration aus _load_tier_config()

    Returns:
        {1: 32, 2: 48, 3: 61}  â†’ Tier â†’ Nachrichtenanzahl
    """
    thresholds = {}
    for tier_num, tier_data in tier_config["tiers"].items():
        if tier_data["enabled"]:
            thresholds[tier_num] = math.floor(
                context_limit * (tier_data["threshold"] / 100)
            )
    return thresholds


def check_and_trigger_cortex_update(
    persona_id: str,
    session_id: int,
    context_limit: int
) -> Optional[int]:
    """
    PrÃ¼ft ob ein Cortex-Update getriggert werden soll und startet es ggf.

    Wird nach jedem erfolgreichen Chat-Response aufgerufen.

    Args:
        persona_id: Aktive Persona-ID
        session_id: Aktuelle Session-ID
        context_limit: Aktuelles Context-Limit (geclampt)

    Returns:
        Tier-Nummer die getriggert wurde, oder None
    """
    # 1. Cortex global deaktiviert?
    config = _load_tier_config()
    if not config["enabled"]:
        return None

    # 2. Keine aktiven Tiers?
    thresholds = _calculate_thresholds(context_limit, config)
    if not thresholds:
        return None

    # 3. Aktuelle Nachrichtenanzahl holen
    message_count = get_message_count(session_id=session_id, persona_id=persona_id)
    if message_count == 0:
        return None

    # 4. Bereits gefeuerte Tiers laden
    fired = get_fired_tiers(persona_id, session_id)

    # 5. Falls noch kein State existiert (z.B. nach Restart), rebuilden
    if not fired and message_count > 0:
        threshold_percents = {
            tier_num: tier_data["threshold"]
            for tier_num, tier_data in config["tiers"].items()
            if tier_data["enabled"]
        }
        # Rebuild markiert Tiers die VOR der jetzigen Nachricht erreicht wurden
        # Wir nutzen (message_count - 1) damit der aktuelle neue Tier trotzdem feuert
        fired = rebuild_from_message_count(
            persona_id, session_id,
            message_count - 1,  # -1: Nur Tiers die VOR dieser Nachricht gefeuert hÃ¤tten
            context_limit, threshold_percents
        )

    # 6. PrÃ¼fen ob ein neuer Tier erreicht wurde
    triggered_tier = None
    for tier_num in sorted(thresholds.keys()):
        threshold = thresholds[tier_num]
        if message_count >= threshold and tier_num not in fired:
            triggered_tier = tier_num
            break  # Nur den niedrigsten neuen Tier auslÃ¶sen

    if triggered_tier is None:
        return None

    # 7. Tier als gefeuert markieren
    mark_tier_fired(persona_id, session_id, triggered_tier)

    log.info(
        "Cortex Tier %d ausgelÃ¶st: %d/%d Nachrichten (Schwelle: %d, contextLimit: %d) â€” Persona: %s, Session: %s",
        triggered_tier, message_count, context_limit,
        thresholds[triggered_tier], context_limit,
        persona_id, session_id
    )

    # 8. Background Cortex-Update starten
    _start_background_cortex_update(
        persona_id=persona_id,
        session_id=session_id,
        context_limit=context_limit,
        triggered_tier=triggered_tier
    )

    return triggered_tier


def _start_background_cortex_update(
    persona_id: str,
    session_id: int,
    context_limit: int,
    triggered_tier: int
) -> None:
    """
    Startet das Cortex-Update in einem Background-Thread.

    Der Thread fÃ¼hrt den tool_use API-Call aus (Schritt 3A: CortexUpdateService).
    Da dies ein separater API-Request ist, blockiert er weder den Chat-Stream
    noch den Response an den Client.

    Args:
        persona_id: Persona-ID
        session_id: Session-ID
        context_limit: Context-Limit fÃ¼r den Konversationskontext
        triggered_tier: Welcher Tier das Update ausgelÃ¶st hat (fÃ¼r Logging)
    """
    def _run_update():
        try:
            from utils.cortex.update_service import CortexUpdateService

            service = CortexUpdateService()
            result = service.execute_update(
                persona_id=persona_id,
                session_id=session_id,
                context_limit=context_limit,
                triggered_tier=triggered_tier
            )

            if result.get('success'):
                log.info(
                    "Cortex-Update abgeschlossen (Tier %d): %d Tool-Calls ausgefÃ¼hrt â€” Persona: %s",
                    triggered_tier,
                    result.get('tool_calls_count', 0),
                    persona_id
                )
            else:
                log.warning(
                    "Cortex-Update fehlgeschlagen (Tier %d): %s â€” Persona: %s",
                    triggered_tier,
                    result.get('error', 'Unbekannter Fehler'),
                    persona_id
                )
        except Exception as e:
            log.error("Cortex-Update Exception (Tier %d): %s", triggered_tier, e)

    thread = threading.Thread(
        target=_run_update,
        name=f"cortex-update-{persona_id}-t{triggered_tier}",
        daemon=True  # Thread stirbt mit dem Hauptprozess
    )
    thread.start()
```

### 4.2 Warum `break` beim ersten neuen Tier?

```python
for tier_num in sorted(thresholds.keys()):
    if message_count >= threshold and tier_num not in fired:
        triggered_tier = tier_num
        break  # â† Nur EINEN Tier pro Nachricht
```

Es wird bewusst nur **ein** Tier pro Nachricht ausgelÃ¶st:

1. **Vermeidet parallele Tool-Use Calls:** Zwei gleichzeitige Cortex-Updates kÃ¶nnten sich gegenseitig Ã¼berschreiben
2. **Progressive Vertiefung:** Tier 1 schreibt erste EindrÃ¼cke, Tier 2 baut darauf auf
3. **Edge Case:** Falls der User mehrere Tiers gleichzeitig Ã¼berspringt (z.B. bei Rebuild nach Restart), wird nur der niedrigste neue Tier ausgelÃ¶st. Die hÃ¶heren Tiers feuern bei der nÃ¤chsten Nachricht.

---

## 5. VollstÃ¤ndiger Flow: Chat â†’ Tier-Check â†’ Cortex-Update

### 5.1 Sequenzdiagramm

```
Client                    Server (chat.py)              TierChecker              Background Thread
  â”‚                            â”‚                            â”‚                         â”‚
  â”‚â”€â”€ POST /chat_stream â”€â”€â”€â”€â”€â”€â–ºâ”‚                            â”‚                         â”‚
  â”‚                            â”‚                            â”‚                         â”‚
  â”‚â—„â”€â”€ SSE: chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                            â”‚                         â”‚
  â”‚â—„â”€â”€ SSE: chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                            â”‚                         â”‚
  â”‚â—„â”€â”€ SSE: chunk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                            â”‚                         â”‚
  â”‚                            â”‚                            â”‚                         â”‚
  â”‚                            â”‚â”€â”€ save_message() â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                         â”‚
  â”‚â—„â”€â”€ SSE: done â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                            â”‚                         â”‚
  â”‚                            â”‚                            â”‚                         â”‚
  â”‚    (Client zeigt Antwort)  â”‚â”€â”€ check_and_trigger() â”€â”€â”€â”€â–ºâ”‚                         â”‚
  â”‚                            â”‚                            â”‚â”€â”€ get_message_count()   â”‚
  â”‚                            â”‚                            â”‚â”€â”€ get_fired_tiers()     â”‚
  â”‚                            â”‚                            â”‚â”€â”€ calculate_thresholds()â”‚
  â”‚                            â”‚                            â”‚                         â”‚
  â”‚                            â”‚                            â”‚â”€â”€ [Tier 2 erreicht!]    â”‚
  â”‚                            â”‚                            â”‚â”€â”€ mark_tier_fired(2)    â”‚
  â”‚                            â”‚                            â”‚                         â”‚
  â”‚                            â”‚                            â”‚â”€â”€ start_background() â”€â”€â–ºâ”‚
  â”‚                            â”‚â—„â”€ return tier=2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                         â”‚
  â”‚                            â”‚                            â”‚                         â”‚
  â”‚    (Response closed)       â”‚                            â”‚  â”Œâ”€ CortexUpdateService â”‚
  â”‚                            â”‚                            â”‚  â”‚  tool_use API-Call    â”‚
  â”‚                            â”‚                            â”‚  â”‚  read memory.md       â”‚
  â”‚                            â”‚                            â”‚  â”‚  write memory.md      â”‚
  â”‚                            â”‚                            â”‚  â”‚  write soul.md        â”‚
  â”‚                            â”‚                            â”‚  â””â”€ Log result           â”‚
  â”‚                            â”‚                            â”‚                         â”‚
```

### 5.2 Timing

| Phase | Dauer | Blockiert Client? |
|-------|-------|:-----------------:|
| Chat-Stream (Chunks) | 2â€“15s | Nein (Streaming) |
| Tier-Check | ~5ms | Nein (nach `done`) |
| Background Cortex-Update | 3â€“10s | **Nein** (eigener Thread) |

### 5.3 Was passiert bei jedem Chat-Response

```python
# Pseudocode â€” vereinfachter Ablauf

def on_chat_response_complete(persona_id, session_id, context_limit):
    """Wird nach jedem erfolgreichen Chat-Response aufgerufen."""

    # 1. Cortex aktiviert?
    config = load_cortex_settings()
    if not config.enabled:
        return

    # 2. Nachrichten zÃ¤hlen
    msg_count = get_message_count(session_id, persona_id)

    # 3. Schwellenwerte berechnen
    #    contextLimit=65, tier1=50% â†’ threshold=32
    thresholds = {
        1: floor(context_limit * 0.50),  # 32
        2: floor(context_limit * 0.75),  # 48
        3: floor(context_limit * 0.95),  # 61
    }

    # 4. Welche Tiers sind schon gefeuert?
    fired = get_fired_tiers(persona_id, session_id)
    # z.B. {1} â†’ Tier 1 hat bereits gefeuert

    # 5. Neuer Tier erreicht?
    for tier in [1, 2, 3]:
        if tier not in fired and msg_count >= thresholds[tier]:
            # Tier 2 bei 48 Nachrichten â†’ JA!
            mark_tier_fired(persona_id, session_id, tier)
            start_background_cortex_update(persona_id, session_id, tier)
            break  # Nur einen Tier pro Nachricht
```

---

## 6. Settings-Struktur fÃ¼r Tier-Konfiguration

### 6.1 Datei: `src/settings/cortex_settings.json`

Diese Datei wurde bereits in Schritt 2C definiert. Die Tier-relevanten Felder:

```json
{
    "enabled": true,
    "tiers": {
        "tier1": {
            "threshold": 50,
            "enabled": true
        },
        "tier2": {
            "threshold": 75,
            "enabled": true
        },
        "tier3": {
            "threshold": 95,
            "enabled": true
        }
    }
}
```

### 6.2 Felder-Referenz

| Feld | Typ | Default | Beschreibung |
|------|-----|---------|-------------|
| `enabled` | `bool` | `true` | Cortex-System global ein/aus |
| `tiers.tier1.threshold` | `int` | `50` | Schwellenwert in % des `contextLimit` â€” Stufe 1 |
| `tiers.tier1.enabled` | `bool` | `true` | Ob Stufe 1 aktiv ist |
| `tiers.tier2.threshold` | `int` | `75` | Schwellenwert in % des `contextLimit` â€” Stufe 2 |
| `tiers.tier2.enabled` | `bool` | `true` | Ob Stufe 2 aktiv ist |
| `tiers.tier3.threshold` | `int` | `95` | Schwellenwert in % des `contextLimit` â€” Stufe 3 |
| `tiers.tier3.enabled` | `bool` | `true` | Ob Stufe 3 aktiv ist |

### 6.3 Validierungsregeln

| Regel | Beschreibung |
|-------|-------------|
| `threshold` âˆˆ [5, 99] | Muss zwischen 5% und 99% liegen |
| `tier1 < tier2 < tier3` | Schwellen mÃ¼ssen aufsteigend sein |
| Mindest-Abstand: 10% | Zwischen Tiers mÃ¼ssen mindestens 10 Prozentpunkte liegen |
| Deaktivierte Tiers | Werden bei der Threshold-Berechnung Ã¼bersprungen |

Die Validierung wird in der Route `PUT /api/cortex/settings` (Schritt 2C) durchgefÃ¼hrt:

```python
def _validate_tier_thresholds(tiers: dict) -> tuple[bool, str]:
    """Validiert die Tier-Schwellenwerte."""
    active_tiers = []
    for key in ['tier1', 'tier2', 'tier3']:
        tier = tiers.get(key, {})
        if tier.get('enabled', True):
            threshold = tier.get('threshold')
            if threshold is not None:
                if not (5 <= threshold <= 99):
                    return False, f"{key}.threshold muss zwischen 5 und 99 liegen"
                active_tiers.append((key, threshold))

    # Aufsteigende Reihenfolge prÃ¼fen
    for i in range(1, len(active_tiers)):
        prev_key, prev_val = active_tiers[i - 1]
        curr_key, curr_val = active_tiers[i]
        if curr_val <= prev_val:
            return False, f"{curr_key}.threshold ({curr_val}) muss grÃ¶ÃŸer als {prev_key}.threshold ({prev_val}) sein"
        if curr_val - prev_val < 10:
            return False, f"Mindestabstand zwischen {prev_key} und {curr_key}: 10 Prozentpunkte"

    return True, ""
```

---

## 7. Edge Cases

### 7.1 `contextLimit` Ã¤ndert sich mid-conversation

**Szenario:** User startet Chat mit `contextLimit=65`, wechselt nach 30 Nachrichten zu `contextLimit=200`.

**Verhalten:**
- Die Schwellenwerte werden bei **jedem** Tier-Check neu berechnet
- Der `context_limit` kommt aus dem aktuellen Request (`data.get('context_limit')`)
- Bereits gefeuerte Tiers bleiben gefeuert (In-Memory State)
- Neue Tier-Schwellen werden gegen die neue Grenze berechnet

```
Vorher (contextLimit=65):
  Tier 1 bei 32 â†’ bereits gefeuert bei Nachricht 32 âœ“
  Tier 2 bei 48 â†’ noch nicht erreicht

User Ã¤ndert contextLimit auf 200:
  Tier 2 bei 150 â†’ weit entfernt (aktuell 30 Nachrichten)
  Tier 3 bei 190 â†’ weit entfernt
```

**Ergebnis:** Die hÃ¶heren Tiers verschieben sich nach hinten. Das ist erwartetes Verhalten â€” ein grÃ¶ÃŸerer Kontext bedeutet mehr Nachrichten bevor ein Update nÃ¶tig ist.

### 7.2 `contextLimit` wird verkleinert

**Szenario:** User hat `contextLimit=200`, wechselt nach 120 Nachrichten zu `contextLimit=65`.

```
Vorher (contextLimit=200):
  Tier 1 bei 100 â†’ gefeuert bei Nachricht 100 âœ“
  Tier 2 bei 150 â†’ noch nicht erreicht

User Ã¤ndert contextLimit auf 65:
  Tier 2 bei 48 â†’ msg_count=120 â‰¥ 48 â†’ NICHT gefeuert (Rebuild markiert als "already fired")
  Tier 3 bei 61 â†’ msg_count=120 â‰¥ 61 â†’ NICHT gefeuert (Rebuild markiert als "already fired")
```

**Verhalten:** Der Rebuild (Abschnitt 2.2, `rebuild_from_message_count`) erkennt, dass bei der neuen Berechnung Tier 2 und 3 schon Ã¼berschritten wÃ¤ren, und markiert sie als "gefeuert" â€” ohne das Update tatsÃ¤chlich auszufÃ¼hren. Das ist konservativ korrekt: Lieber ein Update Ã¼berspringen als den gleichen Kontext doppelt zu verarbeiten.

### 7.3 Session-Wechsel

**Szenario:** User wechselt von Session 5 zu Session 8.

**Verhalten:**
- Der Tier-State ist pro Session (`"{persona_id}:{session_id}"`)
- Session 5 behÃ¤lt ihren Tier-State
- Session 8 hat einen eigenen (mÃ¶glicherweise leeren) State
- Beim ersten Chat in Session 8 wird der State ggf. rebuilt

### 7.4 Persona-Wechsel

**Szenario:** User wechselt von Default-Persona zu Custom-Persona.

**Verhalten:**
- Der Tier-State ist pro Persona+Session Kombination
- Verschiedene Personas haben eigene Cortex-Dateien â†’ eigene Update-Zyklen
- `"default:5"` und `"custom123:5"` sind unabhÃ¤ngige Tier-States

### 7.5 `clear_chat` â€” Chat-Historie wird gelÃ¶scht

**Szenario:** User lÃ¶scht den gesamten Chat.

**Verhalten:**
```python
# In src/routes/chat.py â€” clear_chat()
@chat_bp.route('/clear_chat', methods=['POST'])
def clear_chat():
    clear_chat_history()
    # NEU: Tier-State fÃ¼r die Session zurÃ¼cksetzen
    reset_session(persona_id, session_id)
    return success_response()
```

Der Tier-State wird zurÃ¼ckgesetzt, damit bei neuen Nachrichten die Tiers erneut feuern kÃ¶nnen.

### 7.6 Server-Neustart

**Szenario:** App wird neu gestartet, User chattet in bestehender Session weiter.

**Verhalten:**
1. In-Memory State ist leer (`_fired_tiers = {}`)
2. Beim ersten Tier-Check wird `rebuild_from_message_count()` aufgerufen
3. Basierend auf der aktuellen Nachrichtenanzahl werden vergangene Tiers als "gefeuert" markiert
4. Nur der **nÃ¤chste** noch nicht gefeuerte Tier kann auslÃ¶sen

```
Beispiel: Session hat 50 Nachrichten, contextLimit=65
  â†’ Rebuild: Tier 1 (32) â†’ gefeuert, Tier 2 (48) â†’ gefeuert
  â†’ NÃ¤chster Trigger: Tier 3 bei 61
```

### 7.7 Gleichzeitige Updates vermeiden

**Szenario:** User sendet schnell hintereinander Nachrichten, ein Tier wird getriggert, aber der Background-Update lÃ¤uft noch.

**LÃ¶sung:** Thread-Name als einfache Sperre:

```python
def _start_background_cortex_update(persona_id, session_id, context_limit, triggered_tier):
    """Startet Update nur wenn kein anderer fÃ¼r diese Persona lÃ¤uft."""

    thread_name = f"cortex-update-{persona_id}"

    # PrÃ¼fe ob bereits ein Update-Thread fÃ¼r diese Persona lÃ¤uft
    for thread in threading.enumerate():
        if thread.name == thread_name and thread.is_alive():
            log.info(
                "Cortex-Update Ã¼bersprungen (Tier %d): Vorheriges Update lÃ¤uft noch â€” Persona: %s",
                triggered_tier, persona_id
            )
            return

    thread = threading.Thread(
        target=_run_update,
        name=thread_name,
        daemon=True
    )
    thread.start()
```

> **Hinweis:** `mark_tier_fired()` wird trotzdem aufgerufen â€” der Tier gilt als gefeuert, auch wenn das Update Ã¼bersprungen wurde, weil ein anderes noch lÃ¤uft. Das nÃ¤chste regulÃ¤re Update (nÃ¤chster Tier) wird die Ã„nderungen aufholen.

### 7.8 Kein API-Key konfiguriert

**Szenario:** Cortex ist aktiviert, aber kein API-Key ist vorhanden.

**Verhalten:** Der Tier-Check selbst lÃ¤uft immer (ist nur ein Zahlenvergleich). Das Background-Update in `CortexUpdateService.execute_update()` prÃ¼ft den API-Key und schlÃ¤gt fehl â†’ Log-Warnung. Der Tier wird als gefeuert markiert (kein Retry).

---

## 8. Frontend-Benachrichtigung (optionaler Indikator)

### 8.1 Ãœberblick

Das Frontend kann optional anzeigen, dass ein Cortex-Update im Hintergrund lÃ¤uft. Dies ist **kein** blockierendes UI-Element, sondern ein dezenter Indikator.

### 8.2 Ansatz: SSE-Event im done-Payload

Die einfachste Integration ist ein zusÃ¤tzliches Feld im `done`-Event des Chat-Streams:

```python
# In chat.py â€” generate(), beim 'done' Event:
elif event_type == 'done':
    save_message(event_data['response'], False, character_name, session_id, persona_id=persona_id)
    stream_success = True

    # Tier-Check vorziehen fÃ¼r Frontend-Info
    triggered_tier = None
    try:
        triggered_tier = check_and_trigger_cortex_update(
            persona_id=persona_id,
            session_id=session_id,
            context_limit=context_limit
        )
    except Exception:
        pass

    done_payload = {
        'type': 'done',
        'response': event_data['response'],
        'stats': event_data['stats'],
        'character_name': character_name
    }

    # Optional: Cortex-Update-Info mitsenden
    if triggered_tier is not None:
        done_payload['cortex_update'] = {
            'triggered': True,
            'tier': triggered_tier
        }

    yield f"data: {json.dumps(done_payload)}\n\n"
```

> **Alternative zum Ansatz in Abschnitt 3.2:** Statt den Tier-Check **nach** dem letzten yield auszufÃ¼hren, wird er **vor** dem done-yield ausgefÃ¼hrt, damit das `done`-Event die Cortex-Info enthalten kann. Der Background-Thread wird trotzdem erst nach dem yield gestartet (innerhalb von `check_and_trigger_cortex_update`).

### 8.3 Frontend-Handling in `useMessages.js`

```javascript
// In frontend/src/features/chat/hooks/useMessages.js
// Im onDone-Callback:

onDone: (data) => {
    setIsStreaming(false);
    setIsLoading(false);
    setStreamingStats(data.stats || null);

    // Finalize message
    updateLastMessage({
        message: data.response,
        _streaming: false,
        character_name: data.character_name,
        timestamp: new Date().toISOString(),
        stats: data.stats,
    });

    // NEU: Cortex-Update Benachrichtigung
    if (data.cortex_update?.triggered) {
        // Optional: Event emittieren fÃ¼r UI-Indikator
        window.dispatchEvent(new CustomEvent('cortex-update', {
            detail: { tier: data.cortex_update.tier }
        }));
    }

    if (get('notificationSound', false)) {
        playNotificationSound();
    }
},
```

### 8.4 UI-Indikator Konzept

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Chat-Interface                  â”‚
â”‚                                              â”‚
â”‚  [User] Hey, erzÃ¤hl mir von deinem Tag      â”‚
â”‚                                              â”‚
â”‚  [Persona] Ach, heute war wirklich...        â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ ğŸ§  Cortex aktualisiert sich...  â”‚        â”‚  â† Dezenter Indikator
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚     (verschwindet nach ~3s)
â”‚                                              â”‚
â”‚  [Nachricht eingeben...]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Der Indikator:
- Erscheint nur wenn `cortex_update.triggered === true`
- Zeigt sich als kleine, nicht-blockierende Notification
- Verschwindet nach 3 Sekunden automatisch
- Wird in Schritt 5 (Cortex Settings UI) implementiert

---

## 9. Integration mit `chat/regenerate`

Der Tier-Check muss auch beim Regenerieren von Nachrichten greifen, da die Nachrichtenanzahl sich dabei nicht Ã¤ndert (altes Bot-Msg gelÃ¶scht, neues generiert), aber es ist trotzdem ein vollstÃ¤ndiger Chat-Cycle.

**Entscheidung:** Kein Tier-Check bei Regenerate. Die Nachrichtenanzahl bleibt gleich, also kann kein neuer Tier erreicht werden.

```python
# src/routes/chat.py â€” api_regenerate()
# KEIN Tier-Check nÃ¶tig:
# - delete_last_message() entfernt die alte Bot-Nachricht
# - save_message() speichert die neue Bot-Nachricht
# - Netto-Ã„nderung: 0 Nachrichten â†’ kein neuer Tier mÃ¶glich
```

---

## 10. Neue und geÃ¤nderte Dateien

### 10.1 Neue Dateien

| Datei | Zweck |
|-------|-------|
| `src/utils/cortex/__init__.py` | Package-Init (Exports) |
| `src/utils/cortex/tier_tracker.py` | In-Memory Tracking der gefeuerten Tiers pro Session |
| `src/utils/cortex/tier_checker.py` | Tier-PrÃ¼fung und Background-Update Trigger |

### 10.2 GeÃ¤nderte Dateien

| Datei | Ã„nderung |
|-------|----------|
| `src/routes/chat.py` | Import `tier_checker`, Tier-Check nach Stream-Ende in `chat_stream()` und `clear_chat()` |

### 10.3 AbhÃ¤ngig von (noch nicht implementiert)

| Datei | Schritt | Zweck |
|-------|---------|-------|
| `src/utils/cortex/update_service.py` | 3A + 6 | `CortexUpdateService.execute_update()` â€” der eigentliche Tool-Use Call |
| `src/settings/cortex_settings.json` | 2C | Settings-Datei (wird von `_load_tier_config` gelesen) |

### 10.4 Package-Init

```python
# src/utils/cortex/__init__.py

"""
Cortex Utility Package â€” Aktivierungsstufen und Update-Logik.

Modules:
    tier_tracker â€” In-Memory State fÃ¼r gefeuerte Tiers pro Session
    tier_checker â€” Schwellenwert-PrÃ¼fung und Background-Update Trigger
    update_service â€” CortexUpdateService fÃ¼r Tool-Use API-Calls (Schritt 3A/6)
"""

from utils.cortex.tier_tracker import (
    get_fired_tiers,
    mark_tier_fired,
    reset_session,
    reset_all,
    rebuild_from_message_count
)
from utils.cortex.tier_checker import check_and_trigger_cortex_update

__all__ = [
    'get_fired_tiers',
    'mark_tier_fired',
    'reset_session',
    'reset_all',
    'rebuild_from_message_count',
    'check_and_trigger_cortex_update',
]
```

---

## 11. Zusammenfassung

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         Aktivierungsstufen-Logik       â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚                                        â”‚
                    â”‚  contextLimit = 65 (User-Einstellung)  â”‚
                    â”‚                                        â”‚
                    â”‚  Tier 1: 50% = 32 Nachrichten          â”‚
                    â”‚  Tier 2: 75% = 48 Nachrichten          â”‚
                    â”‚  Tier 3: 95% = 61 Nachrichten          â”‚
                    â”‚                                        â”‚
                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
                    â”‚                                        â”‚
                    â”‚  Nachricht 31: âŒ Kein Tier             â”‚
                    â”‚  Nachricht 32: âœ… Tier 1 â†’ Update      â”‚
                    â”‚  Nachricht 33: âŒ Tier 1 schon gefeuertâ”‚
                    â”‚  ...                                    â”‚
                    â”‚  Nachricht 48: âœ… Tier 2 â†’ Update      â”‚
                    â”‚  ...                                    â”‚
                    â”‚  Nachricht 61: âœ… Tier 3 â†’ Update      â”‚
                    â”‚  Nachricht 62: âŒ Alle Tiers gefeuert  â”‚
                    â”‚                                        â”‚
                    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
                    â”‚                                        â”‚
                    â”‚  Pro Tier: 1x feuern, Background-      â”‚
                    â”‚  Thread, non-blocking, tool_use Call    â”‚
                    â”‚                                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 12. AbhÃ¤ngigkeiten zu anderen Schritten

| AbhÃ¤ngigkeit | Richtung | Details |
|-------------|----------|---------|
| **Schritt 2C** (Cortex API Routes) | â† Voraussetzung | `cortex_settings.json` Lesen/Schreiben, Settings-Endpoints |
| **Schritt 3A** (Tool-Use API Client) | â† Voraussetzung | `ApiClient.tool_request()` fÃ¼r den Background-Update |
| **Schritt 6** (API Integration) | â†’ Nachfolger | `CortexUpdateService` implementiert den eigentlichen Update-Call |
| **Schritt 5** (Cortex Settings UI) | â†’ Nachfolger | UI zum Konfigurieren der Tier-Schwellenwerte |
